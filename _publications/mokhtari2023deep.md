---
title: "Deep learning for graph analysis: application to online human activity recognition"
collection: publications
category: conferences
permalink: /publication/2023-deep-learning-for-graph-analysis:-application-to-online-human-activity-recognition
date: 2023-01-01
venue: "2023 IEEE 22nd International Conference on Trust, Security and Privacy in Computing and Communications (TrustCom)"
bibtexurl: "https://nassimmokhtari.github.io/files/deep-learning-for-graph-analysis:-application-to-online-human-activity-recognition.bib"
citation: "Mokhtari, Nassim and Outlouhou, Mohamed and Nédélec, Alexis and De Loor, Pierre (2023). &quot;Deep learning for graph analysis: application to online human activity recognition.&quot; <i>2023 IEEE 22nd International Conference on Trust, Security and Privacy in Computing and Communications (TrustCom)</i>."
---
Human Activity Recognition (HAR) using sensor data is a time series classification problem. The challenge lies in effectively managing spatial and temporal dependencies while highlighting crucial data variations. This can be accomplished through 3D skeleton data from an RGB+D camera. The hypothesis of this work is that representing 3D skeleton data as spatio-temporal graphs and utilizing graph embedding techniques and deep learning model, composed from Graph Convolutional Networks (GCN), to learn relationships between joints, and Transformers to focus attention on relevant parts, will improve the performance of HAR. We opted to design this model utilizing a Hill Climbing approach. To facilitate real-time action recognition, we employed the sliding window approach. This method involves segmenting the continuous data stream of 3D skeletons, potentially sourced from a Kinect device, into sequences of uniform length. The article shows a significant improvement of the accuracy of the learning according to the state of the art.
